{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Summary\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "This notebook provides a reference procedure of forecasting default rates for Fannie Mae. <br>\n",
    "<br>\n",
    "We first fit logistic regression, regression tree, and xgoost to the training set, and predict the probability of default for the loans in the testing set. The accuracy is measured by the Brier Skill Score (higher BSS indicates more accurate predictions). Next, we provide an example of stacking. \n",
    "<br>\n",
    "The accuracy of the four methods are listed bellow: \n",
    "\n",
    "| Method | Brier Skill Score      \n",
    "| :-: | :-:\n",
    "|logistic regression|  0.0499\n",
    "|regression tree|  0.0495\n",
    "|xgboost | 0.0527\n",
    "|weighted average ensemble | $\\bf{0.0531}$\n",
    "|stacking model-RT | 0.0515\n",
    "|stacking model_XGBOOST| 0.0526\n",
    "\n",
    "\n",
    "\n",
    "## Table of Content <br>\n",
    "[Read in the Training and Testing Data](#Read-in-the-Training-and-Testing-Data)<br>\n",
    "[Function for Calculating the Brier Skill Score](#Function-for-Calculating-the-Brier-Skill-Score)<br>\n",
    "[Logistic Regression](#Logistic-Regression)<br>\n",
    "[Regression Tree](#Regression-Tree)<br>\n",
    "[XGBOOST](#XGBOOST)<br>\n",
    "[Ensemble Model --- Weighted Average](#Ensemble-Model-----Weighted-Average)<br>\n",
    "[Ensemble Model --- Stacking](#Ensemble-Model-----Stacking)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Load the packaes and set up for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# You need to run this line if you are using Jupyter server\n",
    ".libPaths(\"/usr/local/lib/R/site-library\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "4"
      ],
      "text/latex": [
       "4"
      ],
      "text/markdown": [
       "4"
      ],
      "text/plain": [
       "[1] 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(parallel)\n",
    "library(doSNOW)\n",
    "library(foreach)\n",
    "library(Matrix)\n",
    "library(rpart)\n",
    "library(randomForest)\n",
    "library(xgboost)\n",
    "# Set up your multiple cores as separate workers and then make them a cluster.\n",
    "workers <- detectCores()\n",
    "workers\n",
    "cluster <- makeCluster(workers, type = \"SOCK\")\n",
    "registerDoSNOW(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Read in the Training and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">The .rda files allow a user to save their R data structures such as vectors, matrices, and data frames. The file is automatically compressed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "training <- load(\"fannieMae_training.Rda\") \n",
    "testing <- load(\"fannieMae_testing.Rda\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"train.df\"\n",
      "[1] \"test.df\"\n"
     ]
    }
   ],
   "source": [
    "# The data saved in the Rda file already has a variable name.\n",
    "# See the name of the data table saved in the rda file.\n",
    "print(training)\n",
    "print(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Function for Calculating the Brier Skill Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> A Brier score is a way to verify the accuracy of a probability forecast. The score can only be used for binary outcomes, where there are only two possible events. The formula to calculate the Brier score is given by <br>\n",
    "<br>\n",
    "$BS = mean(f_t - o_t)^2$ <br>\n",
    "<br>\n",
    "where $f_t$ is the forecast probability, and $o_t$ is the outcome.\n",
    "\n",
    "A Brier Skill Score (BSS) shows the relative skill of your probability forecast over that of a reference method. A BSS of 1.0 indicates a perfect forecast, while a BSS of 0.0 should indicate the skill of the reference forecast. Less than zero indicates worse than this reference forecast performance. The higher this score is the better. The formula of calculating the BSS is <br>\n",
    "<br>\n",
    "$BSS = 1 - \\frac{BS}{BS^{ref}}$\n",
    "\n",
    "(See http://www.statisticshowto.com/brier-score/ for a detailed introduction of Brier Skill Score) <br>\n",
    "<br>\n",
    "In this study we use a naive forecast as the reference method. The naive forecast is the proportion of default loans in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write a function to calculate the average Brier score.  \n",
    "brier.score <- function(pred, real) {\n",
    " return(mean((pred - real)^2))   \n",
    "}\n",
    "\n",
    "# Establish a reference brier score for a naive forecast\n",
    "# Naive forecast: use the propotion of default loans in the traning set as the prediction \n",
    "# for all the loans in the testing set.\n",
    "train.default.rate <- mean(train.df$DEFAULT_FLAG)\n",
    "test.realizations <- test.df$DEFAULT_FLAG\n",
    "naive.pred <- rep(train.default.rate, length(test.realizations))\n",
    "brier.ref <- brier.score(naive.pred, test.realizations)\n",
    "\n",
    "# Write a function to calculate the Brier skill score\n",
    "skill.score <- function(pred, real, brier.ref) {\n",
    "    brier.score <- brier.score(pred, real) # calculate the Brier score for your predictions.\n",
    "    return(1 - brier.score/ brier.ref)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> Select following variables as predictors in my model:<br>\n",
    "\n",
    "OLTV: ORIGINAL LOAN-TO-VALUE. Calculated by dividing the original loan amount by the value of the property. <br>\n",
    "<br>\n",
    "DTI: Debt-to-Income. Calculated by dividing the borrowerâ€™s total monthly obligations by his or her stable monthly income. <br>\n",
    "<br>\n",
    "CSCORE_B: Borrower Credit Score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"LOAN_ID\"         \"ORIG_CHN\"        \"Seller.Name\"     \"ORIG_RT\"        \n",
      " [5] \"ORIG_AMT\"        \"ORIG_TRM\"        \"ORIG_DTE\"        \"FRST_DTE\"       \n",
      " [9] \"OLTV\"            \"OCLTV\"           \"NUM_BO\"          \"DTI\"            \n",
      "[13] \"CSCORE_B\"        \"FTHB_FLG\"        \"PURPOSE\"         \"PROP_TYP\"       \n",
      "[17] \"NUM_UNIT\"        \"OCC_STAT\"        \"STATE\"           \"ZIP_3\"          \n",
      "[21] \"RELOCATION_FLG\"  \"Monthly.Rpt.Prd\" \"Loan.Age\"        \"Maturity.Date\"  \n",
      "[25] \"MSA\"             \"DEFAULT_FLAG\"   \n"
     ]
    }
   ],
   "source": [
    "# print out column names\n",
    "print(colnames(train.df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select OLTV, DTI, CSCORE_B as predictors. DEFAULT_FLAG is the response variable. \n",
    "train.df.select <- train.df[,c(9, 12, 13, 26)]\n",
    "test.df.select <- test.df[,c(9, 12, 13,  26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logit.reg <- glm(DEFAULT_FLAG~., data = train.df.select, family = \"binomial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predict and test accuracy in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0487473797220818"
      ],
      "text/latex": [
       "0.0487473797220818"
      ],
      "text/markdown": [
       "0.0487473797220818"
      ],
      "text/plain": [
       "[1] 0.04874738"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred.logit.reg <- predict(logit.reg, test.df.select, type = \"response\")\n",
    "\n",
    "# Calculate the Brier Skill Score\n",
    "skill.score(pred.logit.reg, test.df.select$DEFAULT_FLAG, brier.ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> We can also try to add interactions between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = DEFAULT_FLAG ~ . + .^2, family = \"binomial\", data = train.df.select)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.4407  -0.3882  -0.2645  -0.1569   3.9991  \n",
       "\n",
       "Coefficients:\n",
       "                Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)    1.085e+01  6.283e-01  17.269  < 2e-16 ***\n",
       "OLTV          -4.543e-02  7.493e-03  -6.063 1.34e-09 ***\n",
       "DTI           -5.631e-02  8.502e-03  -6.623 3.51e-11 ***\n",
       "CSCORE_B      -2.536e-02  8.908e-04 -28.469  < 2e-16 ***\n",
       "OLTV:DTI       4.712e-05  5.164e-05   0.913    0.361    \n",
       "OLTV:CSCORE_B  1.297e-04  1.027e-05  12.629  < 2e-16 ***\n",
       "DTI:CSCORE_B   1.068e-04  1.166e-05   9.152  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 144580  on 333289  degrees of freedom\n",
       "Residual deviance: 128357  on 333283  degrees of freedom\n",
       "AIC: 128371\n",
       "\n",
       "Number of Fisher Scoring iterations: 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit.reg <- glm(DEFAULT_FLAG ~ . + .^2 , data = train.df.select, family = \"binomial\")\n",
    "summary(logit.reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0499465920074864"
      ],
      "text/latex": [
       "0.0499465920074864"
      ],
      "text/markdown": [
       "0.0499465920074864"
      ],
      "text/plain": [
       "[1] 0.04994659"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred.logit.reg <- predict(logit.reg, test.df.select, type = 'response')\n",
    "skill.score(pred.logit.reg, test.df.select$DEFAULT_FLAG, brier.ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Regression Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "library(rpart)\n",
    "reg.tree <- rpart(DEFAULT_FLAG ~ ., data = train.df.select, control = rpart.control(cp = 0.0001 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Print out feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>OLTV</dt>\n",
       "\t\t<dd>443.86040150697</dd>\n",
       "\t<dt>CSCORE_B</dt>\n",
       "\t\t<dd>387.922884485186</dd>\n",
       "\t<dt>DTI</dt>\n",
       "\t\t<dd>103.185768094656</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[OLTV] 443.86040150697\n",
       "\\item[CSCORE\\textbackslash{}\\_B] 387.922884485186\n",
       "\\item[DTI] 103.185768094656\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "OLTV\n",
       ":   443.86040150697CSCORE_B\n",
       ":   387.922884485186DTI\n",
       ":   103.185768094656\n",
       "\n"
      ],
      "text/plain": [
       "    OLTV CSCORE_B      DTI \n",
       "443.8604 387.9229 103.1858 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg.tree$variable.importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predict and test accuracy in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0495472691096209"
      ],
      "text/latex": [
       "0.0495472691096209"
      ],
      "text/markdown": [
       "0.0495472691096209"
      ],
      "text/plain": [
       "[1] 0.04954727"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg.tree.pred <- predict(reg.tree, test.df.select)\n",
    "\n",
    "# score the regression tree model\n",
    "# skill.score(reg.tree.pred, valid.df[, length(selected) + 1])\n",
    "skill.score(reg.tree.pred, test.df.select$DEFAULT_FLAG, brier.ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xtrain.xgb <- sparse.model.matrix(~ 0 + ., data = train.df.select[,-4])\n",
    "ytrain.xgb <- as.vector(train.df.select$DEFAULT_FLAG)\n",
    "\n",
    "xtest.xgb <- sparse.model.matrix(~ 0 + ., data = test.df.select[,-4])\n",
    "ytest.xgb <- as.vector(test.df.select$DEFAULT_FLAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Generate the xgboost model, also taking advantage of parallel processing\n",
    "xgb.trees <- xgboost(xtrain.xgb, ytrain.xgb, \n",
    "                     max.depth = 3, \n",
    "                     nthread = workers, \n",
    "                     nround = 200, \n",
    "                     objective = \"binary:logistic\",\n",
    "                     verbose = 0)\n",
    "\n",
    "# Tune the model above by increasing/decreasing the depth of each tree \n",
    "# and/or the number of trees (nround)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Print out feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Feature</th><th scope=col>Gain</th><th scope=col>Cover</th><th scope=col>Frequency</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>OLTV     </td><td>0.4361497</td><td>0.3480568</td><td>0.3055130</td></tr>\n",
       "\t<tr><td>CSCORE_B </td><td>0.4309340</td><td>0.4893491</td><td>0.4218989</td></tr>\n",
       "\t<tr><td>DTI      </td><td>0.1329164</td><td>0.1625941</td><td>0.2725881</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " Feature & Gain & Cover & Frequency\\\\\n",
       "\\hline\n",
       "\t OLTV      & 0.4361497 & 0.3480568 & 0.3055130\\\\\n",
       "\t CSCORE\\_B & 0.4309340  & 0.4893491  & 0.4218989 \\\\\n",
       "\t DTI       & 0.1329164 & 0.1625941 & 0.2725881\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Feature | Gain | Cover | Frequency | \n",
       "|---|---|---|\n",
       "| OLTV      | 0.4361497 | 0.3480568 | 0.3055130 | \n",
       "| CSCORE_B  | 0.4309340 | 0.4893491 | 0.4218989 | \n",
       "| DTI       | 0.1329164 | 0.1625941 | 0.2725881 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Feature  Gain      Cover     Frequency\n",
       "1 OLTV     0.4361497 0.3480568 0.3055130\n",
       "2 CSCORE_B 0.4309340 0.4893491 0.4218989\n",
       "3 DTI      0.1329164 0.1625941 0.2725881"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gain indicates the contribution of each feature. \n",
    "# The higher the percentage, the greater the contribution.\n",
    "\n",
    "xgb.importance(colnames(xtrain.xgb), model = xgb.trees)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predict and test accuracy in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0526532043728621"
      ],
      "text/latex": [
       "0.0526532043728621"
      ],
      "text/markdown": [
       "0.0526532043728621"
      ],
      "text/plain": [
       "[1] 0.0526532"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score the model's forecast\n",
    "\n",
    "xgb.trees.pred <- predict(xgb.trees, xtest.xgb)\n",
    "skill.score(xgb.trees.pred, ytest.xgb, brier.ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ensemble Model --- Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m1_weight <- seq(0.1,0.9,0.1)\n",
    "m2_weight <- seq(0.1,0.9,0.1)\n",
    "\n",
    "# set up a matrix to store the Brier skill scores\n",
    "bss_matrix <- matrix(0,9,9)\n",
    "for (i in 1:9) {\n",
    "    for (j in 1:9){\n",
    "        if (m2_weight[j]+ m1_weight[i] > 1) next\n",
    "        ensemble_pred <- m1_weight[i]*pred.logit.reg + reg.tree.pred*m2_weight[j] + xgb.trees.pred*(1-m1_weight[i] - m2_weight[i])\n",
    "        bss_matrix[i,j] <- skill.score(ensemble_pred, test.df.select$DEFAULT_FLAG, brier.ref)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td> 0.053058896</td><td>0.051718749 </td><td>0.04811727  </td><td>0.04225445  </td><td>0.03413030  </td><td>0.02374482  </td><td>0.01109800  </td><td>-0.003810151</td><td>-0.02097964 </td></tr>\n",
       "\t<tr><td> 0.052201945</td><td>0.053155415 </td><td>0.05184755  </td><td>0.04827835  </td><td>0.04244782  </td><td>0.03435596  </td><td>0.02400276  </td><td> 0.011388220</td><td> 0.00000000 </td></tr>\n",
       "\t<tr><td> 0.048709920</td><td>0.051957008 </td><td>0.05294276  </td><td>0.05166718  </td><td>0.04813027  </td><td>0.04233202  </td><td>0.03427244  </td><td> 0.000000000</td><td> 0.00000000 </td></tr>\n",
       "\t<tr><td> 0.042582822</td><td>0.048123528 </td><td>0.05140290  </td><td>0.05242094  </td><td>0.05117764  </td><td>0.04767301  </td><td>0.00000000  </td><td> 0.000000000</td><td> 0.00000000 </td></tr>\n",
       "\t<tr><td> 0.033820651</td><td>0.041654974 </td><td>0.04722796  </td><td>0.05053962  </td><td>0.05158994  </td><td>0.00000000  </td><td>0.00000000  </td><td> 0.000000000</td><td> 0.00000000 </td></tr>\n",
       "\t<tr><td> 0.022423406</td><td>0.032551347 </td><td>0.04041795  </td><td>0.04602323  </td><td>0.00000000  </td><td>0.00000000  </td><td>0.00000000  </td><td> 0.000000000</td><td> 0.00000000 </td></tr>\n",
       "\t<tr><td> 0.008391088</td><td>0.020812646 </td><td>0.03097287  </td><td>0.00000000  </td><td>0.00000000  </td><td>0.00000000  </td><td>0.00000000  </td><td> 0.000000000</td><td> 0.00000000 </td></tr>\n",
       "\t<tr><td>-0.008276303</td><td>0.006438872 </td><td>0.00000000  </td><td>0.00000000  </td><td>0.00000000  </td><td>0.00000000  </td><td>0.00000000  </td><td> 0.000000000</td><td> 0.00000000 </td></tr>\n",
       "\t<tr><td>-0.027578768</td><td>0.000000000 </td><td>0.00000000  </td><td>0.00000000  </td><td>0.00000000  </td><td>0.00000000  </td><td>0.00000000  </td><td> 0.000000000</td><td> 0.00000000 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllllllll}\n",
       "\t  0.053058896 & 0.051718749  & 0.04811727   & 0.04225445   & 0.03413030   & 0.02374482   & 0.01109800   & -0.003810151 & -0.02097964 \\\\\n",
       "\t  0.052201945 & 0.053155415  & 0.05184755   & 0.04827835   & 0.04244782   & 0.03435596   & 0.02400276   &  0.011388220 &  0.00000000 \\\\\n",
       "\t  0.048709920 & 0.051957008  & 0.05294276   & 0.05166718   & 0.04813027   & 0.04233202   & 0.03427244   &  0.000000000 &  0.00000000 \\\\\n",
       "\t  0.042582822 & 0.048123528  & 0.05140290   & 0.05242094   & 0.05117764   & 0.04767301   & 0.00000000   &  0.000000000 &  0.00000000 \\\\\n",
       "\t  0.033820651 & 0.041654974  & 0.04722796   & 0.05053962   & 0.05158994   & 0.00000000   & 0.00000000   &  0.000000000 &  0.00000000 \\\\\n",
       "\t  0.022423406 & 0.032551347  & 0.04041795   & 0.04602323   & 0.00000000   & 0.00000000   & 0.00000000   &  0.000000000 &  0.00000000 \\\\\n",
       "\t  0.008391088 & 0.020812646  & 0.03097287   & 0.00000000   & 0.00000000   & 0.00000000   & 0.00000000   &  0.000000000 &  0.00000000 \\\\\n",
       "\t -0.008276303 & 0.006438872  & 0.00000000   & 0.00000000   & 0.00000000   & 0.00000000   & 0.00000000   &  0.000000000 &  0.00000000 \\\\\n",
       "\t -0.027578768 & 0.000000000  & 0.00000000   & 0.00000000   & 0.00000000   & 0.00000000   & 0.00000000   &  0.000000000 &  0.00000000 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "|  0.053058896 | 0.051718749  | 0.04811727   | 0.04225445   | 0.03413030   | 0.02374482   | 0.01109800   | -0.003810151 | -0.02097964  | \n",
       "|  0.052201945 | 0.053155415  | 0.05184755   | 0.04827835   | 0.04244782   | 0.03435596   | 0.02400276   |  0.011388220 |  0.00000000  | \n",
       "|  0.048709920 | 0.051957008  | 0.05294276   | 0.05166718   | 0.04813027   | 0.04233202   | 0.03427244   |  0.000000000 |  0.00000000  | \n",
       "|  0.042582822 | 0.048123528  | 0.05140290   | 0.05242094   | 0.05117764   | 0.04767301   | 0.00000000   |  0.000000000 |  0.00000000  | \n",
       "|  0.033820651 | 0.041654974  | 0.04722796   | 0.05053962   | 0.05158994   | 0.00000000   | 0.00000000   |  0.000000000 |  0.00000000  | \n",
       "|  0.022423406 | 0.032551347  | 0.04041795   | 0.04602323   | 0.00000000   | 0.00000000   | 0.00000000   |  0.000000000 |  0.00000000  | \n",
       "|  0.008391088 | 0.020812646  | 0.03097287   | 0.00000000   | 0.00000000   | 0.00000000   | 0.00000000   |  0.000000000 |  0.00000000  | \n",
       "| -0.008276303 | 0.006438872  | 0.00000000   | 0.00000000   | 0.00000000   | 0.00000000   | 0.00000000   |  0.000000000 |  0.00000000  | \n",
       "| -0.027578768 | 0.000000000  | 0.00000000   | 0.00000000   | 0.00000000   | 0.00000000   | 0.00000000   |  0.000000000 |  0.00000000  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      [,1]         [,2]        [,3]       [,4]       [,5]       [,6]      \n",
       " [1,]  0.053058896 0.051718749 0.04811727 0.04225445 0.03413030 0.02374482\n",
       " [2,]  0.052201945 0.053155415 0.05184755 0.04827835 0.04244782 0.03435596\n",
       " [3,]  0.048709920 0.051957008 0.05294276 0.05166718 0.04813027 0.04233202\n",
       " [4,]  0.042582822 0.048123528 0.05140290 0.05242094 0.05117764 0.04767301\n",
       " [5,]  0.033820651 0.041654974 0.04722796 0.05053962 0.05158994 0.00000000\n",
       " [6,]  0.022423406 0.032551347 0.04041795 0.04602323 0.00000000 0.00000000\n",
       " [7,]  0.008391088 0.020812646 0.03097287 0.00000000 0.00000000 0.00000000\n",
       " [8,] -0.008276303 0.006438872 0.00000000 0.00000000 0.00000000 0.00000000\n",
       " [9,] -0.027578768 0.000000000 0.00000000 0.00000000 0.00000000 0.00000000\n",
       "      [,7]       [,8]         [,9]       \n",
       " [1,] 0.01109800 -0.003810151 -0.02097964\n",
       " [2,] 0.02400276  0.011388220  0.00000000\n",
       " [3,] 0.03427244  0.000000000  0.00000000\n",
       " [4,] 0.00000000  0.000000000  0.00000000\n",
       " [5,] 0.00000000  0.000000000  0.00000000\n",
       " [6,] 0.00000000  0.000000000  0.00000000\n",
       " [7,] 0.00000000  0.000000000  0.00000000\n",
       " [8,] 0.00000000  0.000000000  0.00000000\n",
       " [9,] 0.00000000  0.000000000  0.00000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>row</th><th scope=col>col</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2</td><td>2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " row & col\\\\\n",
       "\\hline\n",
       "\t 2 & 2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "row | col | \n",
       "|---|\n",
       "| 2 | 2 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     row col\n",
       "[1,] 2   2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bss_matrix # print out the Brier skills score matrix\n",
    "which(bss_matrix == max(bss_matrix), arr.ind = TRUE) # which element in the matrix corresponds to the highest score?\n",
    "# According to the table, the weights put on the predictions from the logistic regression, regression tree and xgboost\n",
    "# should be 0.2,0.2,and 0.6. The highest Brier Skill Score acheived by the weighted average ensemble is 0.0532"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ensemble Model --- Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> This section provides an example combining three base models: a logistic regression, a regression tree, and a xgboost model. We try to use a regression tree and a xgboost model as the stacker model respectively. The procedure can be summarised as follows:<br>\n",
    "\n",
    "1. Split the training set into two parts, a smaller training set and a validation set.\n",
    "2. Train the base models (M1, M2 and M3) by using the smaller training set, and generate predictions from these three models in the validation set.\n",
    "3. Fit a regression tree (or an XGBOOST model) to the predictions generated in Step 2. The dependent variable is DEFAULT_FLAG in the training set and the independent variables are the predictions obtained in Step 2.\n",
    "4. Re-train the base models using the entire training set and generate predictions in the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  Step 1. Split the training set into a smaller training set and a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here is an example of a 75/25 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "333290"
      ],
      "text/latex": [
       "333290"
      ],
      "text/markdown": [
       "333290"
      ],
      "text/plain": [
       "[1] 333290"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "249968"
      ],
      "text/latex": [
       "249968"
      ],
      "text/markdown": [
       "249968"
      ],
      "text/plain": [
       "[1] 249968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "83322"
      ],
      "text/latex": [
       "83322"
      ],
      "text/markdown": [
       "83322"
      ],
      "text/plain": [
       "[1] 83322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(nrowTrain <- nrow(train.df.select))\n",
    "(nrowSmallTrain <- round(nrowTrain*0.75))\n",
    "(nrowvalid <- nrowTrain - nrowSmallTrain)\n",
    "\n",
    "set.seed(201)\n",
    "# generate row numbers of the training set.\n",
    "rowIndicesSmallTrain <- sample(1:nrowTrain, size = nrowSmallTrain, replace = FALSE) \n",
    "smalltrain.df <- train.df.select[rowIndicesSmallTrain, ]\n",
    "valid.df <- train.df.select[-rowIndicesSmallTrain, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 2. Train the base models in the small training set and generate predictions in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "M1 <- glm(DEFAULT_FLAG ~  . + (.)^2, data = smalltrain.df, family = \"binomial\")\n",
    "M1.predict <- predict.glm(M1, valid.df, type = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Regression tree\n",
    "M2 <- rpart(DEFAULT_FLAG ~ ., \n",
    "                  data = smalltrain.df, \n",
    "                  control = rpart.control(cp = 0.0001), \n",
    "                  method = \"anova\")\n",
    "M2.predict <-  predict(M2, valid.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# XGBOOST\n",
    "smallxtrain.xgb <- sparse.model.matrix(~ 0 + ., data = smalltrain.df[,-4])\n",
    "smallytrain.xgb <- as.vector(smalltrain.df$DEFAULT_FLAG)\n",
    "\n",
    "xvalid.xgb <- sparse.model.matrix(~ 0 + ., data = valid.df[,-4])\n",
    "yvalid.xgb <- as.vector(valid.df$DEFAULT_FLAG)\n",
    "\n",
    "M3 <- xgboost(smallxtrain.xgb, smallytrain.xgb, \n",
    "                     max.depth = 3, \n",
    "                     nthread = workers, \n",
    "                     nround = 200, \n",
    "                     objective = \"binary:logistic\",\n",
    "                     verbose = 0)\n",
    "\n",
    "\n",
    "M3_predict <- predict(M3, xvalid.xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 4. Fit a stacker model to the predictions generated in Step 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a data frame as the input for the stacking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>DEFAULT_FLAG</th><th scope=col>M1.predict</th><th scope=col>M2.predict</th><th scope=col>M3.predict</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0         </td><td>0.01121448</td><td>0.01419676</td><td>0.01032643</td></tr>\n",
       "\t<tr><td>0         </td><td>0.03839097</td><td>0.03869611</td><td>0.03180914</td></tr>\n",
       "\t<tr><td>0         </td><td>0.11456575</td><td>0.14865616</td><td>0.12453716</td></tr>\n",
       "\t<tr><td>1         </td><td>0.05028825</td><td>0.07231588</td><td>0.09881273</td></tr>\n",
       "\t<tr><td>0         </td><td>0.17325774</td><td>0.09760226</td><td>0.11512689</td></tr>\n",
       "\t<tr><td>0         </td><td>0.09776487</td><td>0.09623558</td><td>0.10042360</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " DEFAULT\\_FLAG & M1.predict & M2.predict & M3.predict\\\\\n",
       "\\hline\n",
       "\t 0          & 0.01121448 & 0.01419676 & 0.01032643\\\\\n",
       "\t 0          & 0.03839097 & 0.03869611 & 0.03180914\\\\\n",
       "\t 0          & 0.11456575 & 0.14865616 & 0.12453716\\\\\n",
       "\t 1          & 0.05028825 & 0.07231588 & 0.09881273\\\\\n",
       "\t 0          & 0.17325774 & 0.09760226 & 0.11512689\\\\\n",
       "\t 0          & 0.09776487 & 0.09623558 & 0.10042360\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "DEFAULT_FLAG | M1.predict | M2.predict | M3.predict | \n",
       "|---|---|---|---|---|---|\n",
       "| 0          | 0.01121448 | 0.01419676 | 0.01032643 | \n",
       "| 0          | 0.03839097 | 0.03869611 | 0.03180914 | \n",
       "| 0          | 0.11456575 | 0.14865616 | 0.12453716 | \n",
       "| 1          | 0.05028825 | 0.07231588 | 0.09881273 | \n",
       "| 0          | 0.17325774 | 0.09760226 | 0.11512689 | \n",
       "| 0          | 0.09776487 | 0.09623558 | 0.10042360 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  DEFAULT_FLAG M1.predict M2.predict M3.predict\n",
       "1 0            0.01121448 0.01419676 0.01032643\n",
       "2 0            0.03839097 0.03869611 0.03180914\n",
       "3 0            0.11456575 0.14865616 0.12453716\n",
       "4 1            0.05028825 0.07231588 0.09881273\n",
       "5 0            0.17325774 0.09760226 0.11512689\n",
       "6 0            0.09776487 0.09623558 0.10042360"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stacker.df <- data.frame(DEFAULT_FLAG = valid.df$DEFAULT_FLAG, \n",
    "                         M1.predict = M1.predict, \n",
    "                         M2.predict = M2.predict,\n",
    "                         M3.predict = M3_predict)\n",
    "\n",
    "head(stacker.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Fit a regression tree to the predictions as stacker model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stackerModel_1 <- rpart(DEFAULT_FLAG ~ ., \n",
    "                  data = stacker.df, \n",
    "                  control = rpart.control(cp = 0.0004), # Different settings of cp have been examined. Here 0.0004 gives the best accuracy in the test set.\n",
    "                  method = \"anova\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Fit an XGBOOST model to the predictions as stacker model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stacker.df.xgb <- model.matrix(~ 0 + ., data = stacker.df[,-1])\n",
    "stacker.y <- as.vector(stacker.df[,1])\n",
    "stackerModel_2 <- xgboost(stacker.df.xgb, stacker.y,\n",
    "                     max.depth = 3, \n",
    "                     nthread = workers, \n",
    "                     nround = 20, \n",
    "                     objective = \"binary:logistic\",\n",
    "                     verbose = 0)\n",
    "# Different settings of max.depth and nround have been examined. \n",
    "# max.depth = 3 and nround = 20 provide the highest Brier Skill Score in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 5. Re-train the base models using the entire training set and generate predictions for the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Re-train the base models to the entire training set (train.df.select)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "M1.trainAll <- glm(DEFAULT_FLAG ~ . + .^2, \n",
    "                   data = train.df.select, family = \"binomial\")\n",
    "\n",
    "M2.trainAll <- rpart(DEFAULT_FLAG ~ ., \n",
    "                  data = train.df.select, \n",
    "                  control = rpart.control(cp = 0.0001), \n",
    "                  method = \"anova\")\n",
    "\n",
    "M3.trainAll <- xgboost(xtrain.xgb, ytrain.xgb, \n",
    "                     max.depth = 3, \n",
    "                     nthread = workers, \n",
    "                     nround = 200, \n",
    "                     objective = \"binary:logistic\",\n",
    "                     verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Generate predictions for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "M1.predict.test <- predict(M1.trainAll, test.df.select, type = \"response\")\n",
    "M2.predict.test <- predict(M2.trainAll, test.df.select)\n",
    "M3.predict.test <- predict(M3.trainAll, xtest.xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use M1.predict.test, M2.predict.test and M3.predict.test as inputs to the stacker model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0515264482551288"
      ],
      "text/latex": [
       "0.0515264482551288"
      ],
      "text/markdown": [
       "0.0515264482551288"
      ],
      "text/plain": [
       "[1] 0.05152645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict.variables <- data.frame('M1.predict' = M1.predict.test, \n",
    "                                'M2.predict' = M2.predict.test,\n",
    "                                'M3.predict' = M3.predict.test)\n",
    "\n",
    "# Predict from stacker model 1 --- regression tree\n",
    "stacker.predict.rt <- predict(stackerModel_1, predict.variables)\n",
    "\n",
    "# Score the stacker model's prediction\n",
    "skill.score(stacker.predict.rt, test.df.select$DEFAULT_FLAG, brier.ref) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0525584289602513"
      ],
      "text/latex": [
       "0.0525584289602513"
      ],
      "text/markdown": [
       "0.0525584289602513"
      ],
      "text/plain": [
       "[1] 0.05255843"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict from stacker model 2 --- XGBOOST, and calculate the Brier Skill Score\n",
    "predict.variables.xgb <- model.matrix(~ 0 + ., data = predict.variables)\n",
    "stacker.predict.xgb <- predict(stackerModel_2, predict.variables.xgb)\n",
    "\n",
    "# Score the stacker model's prediction\n",
    "skill.score(stacker.predict.xgb, test.df.select$DEFAULT_FLAG, brier.ref) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
